#!/usr/bin/env python3
"""
éŸ³æ¥½å¤‰æ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ Step 1: é«˜å“è³ªéŸ³æºåˆ†é›¢
Demucsã®é«˜å“è³ªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦MP3ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒœãƒ¼ã‚«ãƒ«ãƒ»ãƒ‰ãƒ©ãƒ ãƒ»ãƒ™ãƒ¼ã‚¹ãƒ»ãã®ä»–ã«åˆ†é›¢

Features:
- è¤‡æ•°Demucsãƒ¢ãƒ‡ãƒ«å¯¾å¿œ (htdemucs_ft, mdx_extra_q, htdemucs_6s)
- é«˜å“è³ªåˆ†é›¢è¨­å®š (float32, overlapèª¿æ•´)
- å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
- A/Bãƒ†ã‚¹ãƒˆæ©Ÿèƒ½
- å“è³ªè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ 

Requirements:
- Python 3.11
- PyTorch 2.7.1+cu118 (CUDAå¯¾å¿œ)
- Demucs 4.0.1
- librosa 0.11.0
"""

import os
import sys
import time
import json
import argparse
import subprocess
from pathlib import Path
import torch
import librosa
import soundfile as sf
import numpy as np
import matplotlib.pyplot as plt
from typing import Dict, List, Tuple, Optional
from datetime import datetime

class EnhancedMusicSeparator:
    """é«˜å“è³ªéŸ³æºåˆ†é›¢ã‚¯ãƒ©ã‚¹"""
    
    # åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«å®šç¾©
    AVAILABLE_MODELS = {
        "htdemucs": {
            "name": "htdemucs",
            "quality": "standard",
            "speed": "fast",
            "description": "æ¨™æº–ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰"
        },
        "htdemucs_ft": {
            "name": "htdemucs_ft", 
            "quality": "high",
            "speed": "medium",
            "description": "ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç‰ˆï¼ˆæ¨å¥¨ï¼‰"
        },
        "mdx_extra_q": {
            "name": "mdx_extra_q",
            "quality": "highest", 
            "speed": "slow",
            "description": "æœ€é«˜å“è³ªç‰ˆ"
        },
        "htdemucs_6s": {
            "name": "htdemucs_6s",
            "quality": "high",
            "speed": "medium", 
            "description": "6ã‚¹ãƒ†ãƒ åˆ†é›¢ç‰ˆ"
        }
    }
    
    def __init__(self, 
                 model_name: str = "htdemucs_ft",
                 quality_preset: str = "high",
                 use_preprocessing: bool = True):
        """
        åˆæœŸåŒ–
        
        Args:
            model_name: ä½¿ç”¨ã™ã‚‹Demucsãƒ¢ãƒ‡ãƒ«å
            quality_preset: å“è³ªãƒ—ãƒªã‚»ãƒƒãƒˆï¼ˆstandard/high/highestï¼‰
            use_preprocessing: å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ä½¿ç”¨
        """
        self.model_name = model_name
        self.quality_preset = quality_preset
        self.use_preprocessing = use_preprocessing
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        print(f"ğŸµ EnhancedMusicSeparatoråˆæœŸåŒ–")
        print(f"   ãƒ¢ãƒ‡ãƒ«: {self.model_name}")
        print(f"   å“è³ªãƒ—ãƒªã‚»ãƒƒãƒˆ: {self.quality_preset}")
        print(f"   å‰å‡¦ç†: {'æœ‰åŠ¹' if self.use_preprocessing else 'ç„¡åŠ¹'}")
        print(f"   ãƒ‡ãƒã‚¤ã‚¹: {self.device}")
        
        if self.device == "cuda":
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            print(f"   GPU: {gpu_name} ({gpu_memory:.1f}GB)")
        
        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±è¡¨ç¤º
        if model_name in self.AVAILABLE_MODELS:
            model_info = self.AVAILABLE_MODELS[model_name]
            print(f"   èª¬æ˜: {model_info['description']}")
        else:
            print(f"   âš ï¸ æœªçŸ¥ã®ãƒ¢ãƒ‡ãƒ«ã§ã™: {model_name}")
    
    def get_quality_settings(self) -> Dict[str, any]:
        """å“è³ªãƒ—ãƒªã‚»ãƒƒãƒˆã«åŸºã¥ãè¨­å®šã‚’å–å¾—"""
        settings = {
            "standard": {
                "overlap": 0.5,
                "use_float32": False,
                "mp3_preset": 2,
                "segment": 4
            },
            "high": {
                "overlap": 0.75,
                "use_float32": True,
                "mp3_preset": 2,
                "segment": 7
            },
            "highest": {
                "overlap": 0.85,
                "use_float32": True,
                "mp3_preset": 2,
                "segment": 12
            }
        }
        return settings.get(self.quality_preset, settings["high"])
    
    def preprocess_audio(self, input_file: str, output_file: str = None) -> str:
        """éŸ³å£°å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
        if not self.use_preprocessing:
            return input_file
        
        print(f"ğŸ”§ éŸ³å£°å‰å‡¦ç†é–‹å§‹")
        
        # å‰å‡¦ç†ç”¨ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«
        if output_file is None:
            input_path = Path(input_file)
            output_file = str(input_path.parent / f"{input_path.stem}_preprocessed.wav")
        
        try:
            # éŸ³å£°èª­ã¿è¾¼ã¿
            y, sr = librosa.load(input_file, sr=44100)
            
            # 1. ãƒ”ãƒ¼ã‚¯æ­£è¦åŒ– (-1dBFS)
            peak_norm_factor = 0.891  # -1dBFS
            y_normalized = y * (peak_norm_factor / np.max(np.abs(y)))
            
            # 2. RMSæ­£è¦åŒ– (-23 LUFSç›¸å½“)
            target_rms = 0.1  # -23 LUFSç›¸å½“
            current_rms = np.sqrt(np.mean(y_normalized**2))
            if current_rms > 0:
                rms_factor = target_rms / current_rms
                y_normalized = y_normalized * min(rms_factor, 1.0)  # ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°é˜²æ­¢
            
            # 3. DCæˆåˆ†é™¤å»
            y_processed = y_normalized - np.mean(y_normalized)
            
            # ä¿å­˜
            sf.write(output_file, y_processed, sr)
            
            print(f"   å‰å‡¦ç†å®Œäº†: {Path(output_file).name}")
            print(f"   ãƒ”ãƒ¼ã‚¯: {np.max(np.abs(y_processed)):.3f}")
            print(f"   RMS: {np.sqrt(np.mean(y_processed**2)):.3f}")
            
            return output_file
            
        except Exception as e:
            print(f"   âš ï¸ å‰å‡¦ç†ã‚¨ãƒ©ãƒ¼ã€ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨: {e}")
            return input_file
    
    def separate_audio(self, input_file: str, output_dir: str = None) -> Dict[str, str]:
        """
        é«˜å“è³ªéŸ³æºåˆ†é›¢ã‚’å®Ÿè¡Œ
        
        Args:
            input_file: å…¥åŠ›éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            
        Returns:
            åˆ†é›¢ã•ã‚ŒãŸå„ãƒˆãƒ©ãƒƒã‚¯ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹è¾æ›¸
        """
        input_path = Path(input_file)
        if not input_path.exists():
            raise FileNotFoundError(f"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_file}")
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
        if output_dir is None:
            output_dir = input_path.parent / f"{input_path.stem}_separated_enhanced"
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # å‰å‡¦ç†å®Ÿè¡Œ
        processed_file = self.preprocess_audio(input_file)
        
        print(f"\nğŸ”„ é«˜å“è³ªéŸ³æºåˆ†é›¢é–‹å§‹")
        print(f"   å…¥åŠ›: {input_file}")
        print(f"   å‡¦ç†æ¸ˆã¿: {Path(processed_file).name}")
        print(f"   å‡ºåŠ›: {output_dir}")
        
        # å‡¦ç†æ™‚é–“æ¸¬å®šé–‹å§‹
        start_time = time.time()
        
        try:
            # å“è³ªè¨­å®šå–å¾—
            quality_settings = self.get_quality_settings()
            
            # Demucsã‚³ãƒãƒ³ãƒ‰æ§‹ç¯‰
            cmd = [
                "python", "-m", "demucs.separate",
                "-n", self.model_name,
                "-o", str(output_path),
                "-d", self.device,
                "--overlap", str(quality_settings["overlap"])
            ]
            
            # é«˜å“è³ªè¨­å®šè¿½åŠ 
            if quality_settings["use_float32"]:
                cmd.append("--float32")
            
            if quality_settings["segment"] > 4:
                cmd.extend(["--segment", str(quality_settings["segment"])])
            
            # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«è¿½åŠ 
            cmd.append(processed_file)
            
            print(f"   å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰: {' '.join(cmd)}")
            
            # ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã§å®Ÿè¡Œ
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                cwd=os.getcwd()
            )
            
            if result.returncode != 0:
                print(f"âŒ Demucså®Ÿè¡Œã‚¨ãƒ©ãƒ¼:")
                print(f"   stdout: {result.stdout}")
                print(f"   stderr: {result.stderr}")
                raise RuntimeError(f"Demucså®Ÿè¡Œå¤±æ•—: {result.stderr}")
            
        except Exception as e:
            print(f"âŒ éŸ³æºåˆ†é›¢ã‚¨ãƒ©ãƒ¼: {e}")
            raise
        finally:
            # å‰å‡¦ç†ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            if processed_file != input_file and os.path.exists(processed_file):
                os.remove(processed_file)
        
        # å‡¦ç†æ™‚é–“æ¸¬å®šçµ‚äº†
        end_time = time.time()
        processing_time = end_time - start_time
        
        # åˆ†é›¢ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
        separated_files = self._find_separated_files(output_path, Path(processed_file).stem)
        
        print(f"âœ… é«˜å“è³ªéŸ³æºåˆ†é›¢å®Œäº†")
        print(f"   å‡¦ç†æ™‚é–“: {processing_time:.2f}ç§’")
        print(f"   åˆ†é›¢ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(separated_files)}")
        
        # åˆ†é›¢çµæœã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        self._save_separation_metadata(output_path, {
            "model": self.model_name,
            "quality_preset": self.quality_preset,
            "processing_time": processing_time,
            "settings": quality_settings,
            "separated_files": separated_files,
            "timestamp": datetime.now().isoformat()
        })
        
        return separated_files
    
    def _find_separated_files(self, output_dir: Path, stem: str) -> Dict[str, str]:
        """åˆ†é›¢ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
        separated_files = {}
        
        # Demucsã®å‡ºåŠ›æ§‹é€ ã‚’ç¢ºèª
        model_output_dir = output_dir / self.model_name / stem
        
        if not model_output_dir.exists():
            print(f"âš ï¸ åˆ†é›¢ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_output_dir}")
            return separated_files
        
        # htdemucs_6s ã¯6ã‚¹ãƒ†ãƒ å‡ºåŠ›
        if self.model_name == "htdemucs_6s":
            track_names = ["vocals", "drums", "bass", "piano", "guitar", "other"]
        else:
            track_names = ["vocals", "drums", "bass", "other"]
        
        for track in track_names:
            track_file = model_output_dir / f"{track}.wav"
            if track_file.exists():
                separated_files[track] = str(track_file)
                print(f"   {track}: {track_file}")
            else:
                print(f"   âš ï¸ {track}: ãƒ•ã‚¡ã‚¤ãƒ«ãªã—")
        
        return separated_files
    
    def _save_separation_metadata(self, output_dir: Path, metadata: Dict):
        """åˆ†é›¢ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        metadata_file = output_dir / "separation_metadata.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        print(f"   ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {metadata_file.name}")
    
    def analyze_separation_quality(self, separated_files: Dict[str, str]) -> Dict[str, Dict]:
        """è©³ç´°ãªåˆ†é›¢å“è³ªåˆ†æ"""
        print(f"\nğŸ“Š è©³ç´°åˆ†é›¢å“è³ªåˆ†æ")
        
        analysis = {}
        
        for track_name, file_path in separated_files.items():
            if not os.path.exists(file_path):
                continue
                
            try:
                # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
                y, sr = librosa.load(file_path, sr=None)
                
                # åŸºæœ¬çµ±è¨ˆ
                duration = len(y) / sr
                rms_energy = librosa.feature.rms(y=y)[0].mean()
                zero_crossing_rate = librosa.feature.zero_crossing_rate(y)[0].mean()
                spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)[0].mean()
                
                # é«˜åº¦ãªåˆ†æ
                spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0].mean()
                spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0].mean()
                mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
                mfcc_mean = np.mean(mfccs, axis=1)
                
                # å‹•çš„ç¯„å›²
                dynamic_range = np.max(np.abs(y)) - np.min(np.abs(y))
                
                analysis[track_name] = {
                    "duration": duration,
                    "rms_energy": float(rms_energy),
                    "zero_crossing_rate": float(zero_crossing_rate),
                    "spectral_centroid": float(spectral_centroid),
                    "spectral_bandwidth": float(spectral_bandwidth),
                    "spectral_rolloff": float(spectral_rolloff),
                    "dynamic_range": float(dynamic_range),
                    "mfcc_features": mfcc_mean.tolist(),
                    "file_size": os.path.getsize(file_path) / (1024*1024)  # MB
                }
                
                print(f"   {track_name}:")
                print(f"     æ™‚é–“: {duration:.2f}ç§’")
                print(f"     ã‚¨ãƒãƒ«ã‚®ãƒ¼: {rms_energy:.4f}")
                print(f"     ã‚¹ãƒšã‚¯ãƒˆãƒ«ä¸­å¿ƒ: {spectral_centroid:.1f}Hz")
                print(f"     å‹•çš„ç¯„å›²: {dynamic_range:.4f}")
                print(f"     ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {analysis[track_name]['file_size']:.2f}MB")
                
            except Exception as e:
                print(f"   âŒ {track_name} åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                analysis[track_name] = {"error": str(e)}
        
        return analysis


def create_separation_comparison(input_file: str, models: List[str] = None) -> Dict[str, Dict]:
    """è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã§A/Bãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    if models is None:
        models = ["htdemucs", "htdemucs_ft", "mdx_extra_q"]
    
    print(f"\nğŸ”„ A/Bãƒ†ã‚¹ãƒˆé–‹å§‹: {len(models)}ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ")
    
    results = {}
    input_path = Path(input_file)
    base_output_dir = input_path.parent / f"{input_path.stem}_comparison"
    base_output_dir.mkdir(parents=True, exist_ok=True)
    
    for model in models:
        print(f"\n--- {model} ãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œ ---")
        
        try:
            separator = EnhancedMusicSeparator(
                model_name=model,
                quality_preset="high",
                use_preprocessing=True
            )
            
            model_output_dir = base_output_dir / model
            separated_files = separator.separate_audio(input_file, str(model_output_dir))
            
            if separated_files:
                analysis = separator.analyze_separation_quality(separated_files)
                
                results[model] = {
                    "separated_files": separated_files,
                    "analysis": analysis,
                    "model_info": EnhancedMusicSeparator.AVAILABLE_MODELS.get(model, {})
                }
                
                print(f"   âœ… {model} å®Œäº†")
            else:
                print(f"   âŒ {model} å¤±æ•—")
                
        except Exception as e:
            print(f"   âŒ {model} ã‚¨ãƒ©ãƒ¼: {e}")
            results[model] = {"error": str(e)}
    
    # æ¯”è¼ƒçµæœä¿å­˜
    comparison_file = base_output_dir / "comparison_results.json"
    with open(comparison_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“Š æ¯”è¼ƒçµæœä¿å­˜: {comparison_file}")
    return results


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(description="é«˜å“è³ªéŸ³æºåˆ†é›¢ã‚·ã‚¹ãƒ†ãƒ ")
    parser.add_argument("--input", "-i", type=str, help="å…¥åŠ›éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«")
    parser.add_argument("--output", "-o", type=str, help="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--model", "-m", type=str, default="htdemucs_ft",
                       choices=list(EnhancedMusicSeparator.AVAILABLE_MODELS.keys()),
                       help="ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«")
    parser.add_argument("--quality", "-q", type=str, default="high",
                       choices=["standard", "high", "highest"],
                       help="å“è³ªãƒ—ãƒªã‚»ãƒƒãƒˆ")
    parser.add_argument("--no-preprocessing", action="store_true",
                       help="å‰å‡¦ç†ã‚’ç„¡åŠ¹åŒ–")
    parser.add_argument("--compare", action="store_true",
                       help="è¤‡æ•°ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒå®Ÿè¡Œ")
    
    args = parser.parse_args()
    
    print("ğŸµ é«˜å“è³ªéŸ³æ¥½å¤‰æ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ Step 1: éŸ³æºåˆ†é›¢")
    print("=" * 60)
    
    # ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
    work_dir = Path.home() / "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ" / "conversion_music"
    work_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸ“ ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {work_dir}")
    
    # GPUç’°å¢ƒç¢ºèª
    if torch.cuda.is_available():
        print(f"ğŸš€ CUDAåˆ©ç”¨å¯èƒ½: {torch.version.cuda}")
        print(f"   GPUæ•°: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            print(f"   GPU {i}: {torch.cuda.get_device_name(i)}")
    else:
        print("âš ï¸ CUDAåˆ©ç”¨ä¸å¯ã€CPUã§å®Ÿè¡Œã—ã¾ã™")
    
    # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
    if args.input:
        input_file = args.input
    else:
        # ãƒ†ã‚¹ãƒˆç”¨éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
        test_files = []
        audio_extensions = ['.mp3', '.wav', '.m4a', '.flac', '.aac', '.ogg']
        
        for ext in audio_extensions:
            test_files.extend(work_dir.glob(f"*{ext}"))
            test_files.extend(work_dir.glob(f"*{ext.upper()}"))
        
        test_files = list(set(test_files))
        
        if not test_files:
            print("\nğŸ“ å…¥åŠ›éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            print("   --input ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã™ã‚‹ã‹ã€")
            print(f"   {work_dir}/ ã«éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®ã—ã¦ãã ã•ã„")
            return
        
        input_file = str(test_files[0])
        print(f"\nğŸµ è‡ªå‹•é¸æŠ: {Path(input_file).name}")
    
    # åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«è¡¨ç¤º
    print(f"\nğŸ”§ åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«:")
    for model_name, model_info in EnhancedMusicSeparator.AVAILABLE_MODELS.items():
        marker = "ğŸ‘ˆ" if model_name == args.model else "  "
        print(f"   {marker} {model_name}: {model_info['description']}")
    
    try:
        if args.compare:
            # è¤‡æ•°ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ
            results = create_separation_comparison(input_file)
            print(f"\nâœ… æ¯”è¼ƒãƒ†ã‚¹ãƒˆå®Œäº†! çµæœã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        else:
            # å˜ä¸€ãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œ
            separator = EnhancedMusicSeparator(
                model_name=args.model,
                quality_preset=args.quality,
                use_preprocessing=not args.no_preprocessing
            )
            
            separated_files = separator.separate_audio(input_file, args.output)
            
            if separated_files:
                # åˆ†é›¢å“è³ªåˆ†æ
                analysis = separator.analyze_separation_quality(separated_files)
                
                print(f"\nâœ… é«˜å“è³ªåˆ†é›¢å®Œäº†!")
                print(f"   æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: MIDIå¤‰æ› (Step 2)")
                print(f"   åˆ†é›¢ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
                for track, path in separated_files.items():
                    print(f"     {track}: {Path(path).name}")
            else:
                print(f"âŒ åˆ†é›¢ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"\nğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°:")
        print(f"   1. ä»®æƒ³ç’°å¢ƒã®æœ‰åŠ¹åŒ–: source music_conversion_env/bin/activate")
        print(f"   2. Demucsã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª: pip list | grep demucs")
        print(f"   3. CUDAç’°å¢ƒç¢ºèª: python -c 'import torch; print(torch.cuda.is_available())'")
        print(f"   4. ãƒ¢ãƒ‡ãƒ«ç¢ºèª: python -c 'import demucs.api; print(demucs.api.list_models())'")


if __name__ == "__main__":
    main()