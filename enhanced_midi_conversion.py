#!/usr/bin/env python3
"""
é«˜å“è³ªéŸ³æºåˆ†é›¢çµæœã‹ã‚‰ã®MIDIå¤‰æ›
enhanced_music_separation.pyã§åˆ†é›¢ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¯¾è±¡ã«MIDIå¤‰æ›å®Ÿè¡Œ

Features:
- htdemucs_fté«˜å“è³ªåˆ†é›¢çµæœå¯¾å¿œ
- å“è³ªæ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
- æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®é€£æº
"""

import os
import sys
import json
import argparse
from pathlib import Path
from typing import Dict, List, Optional

# MIDIå¤‰æ›ã‚·ã‚¹ãƒ†ãƒ ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.append(str(Path(__file__).parent))
from midi_quantizer import MIDIQuantizer, QuantizationSettings

# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import numpy as np
import librosa
import pretty_midi
import warnings
warnings.filterwarnings('ignore')

try:
    from basic_pitch.inference import predict_and_save, predict
    from basic_pitch import ICASSP_2022_MODEL_PATH
    BASIC_PITCH_AVAILABLE = True
    print("âœ… basic-pitchåˆ©ç”¨å¯èƒ½")
except ImportError:
    print("âš ï¸ basic-pitch ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    BASIC_PITCH_AVAILABLE = False


class MIDIConverter:
    """éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯ã‚’MIDIã«å¤‰æ›ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, quantization_settings=None, original_audio_file=None):
        self.sample_rate = 22050
        self.quantization_settings = quantization_settings
        self.quantizer = None
        self.original_audio_file = original_audio_file
        
        if quantization_settings and quantization_settings.enabled:
            self.quantizer = MIDIQuantizer(quantization_settings)
            print("ğŸ¼ MIDIConverteråˆæœŸåŒ–å®Œäº†ï¼ˆé‡å­åŒ–æ©Ÿèƒ½ä»˜ãï¼‰")
        else:
            print("ğŸ¼ MIDIConverteråˆæœŸåŒ–å®Œäº†")
    
    def convert_separated_tracks(self, separated_files: Dict[str, str], output_dir: str = None) -> Dict[str, str]:
        """åˆ†é›¢ã•ã‚ŒãŸãƒˆãƒ©ãƒƒã‚¯ã‚’MIDIã«å¤‰æ›"""
        if not separated_files:
            raise ValueError("åˆ†é›¢ãƒ•ã‚¡ã‚¤ãƒ«ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        if output_dir is None:
            first_file = Path(next(iter(separated_files.values())))
            output_dir = first_file.parent.parent / "midi_tracks"
        
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        print(f"\\nğŸ¼ MIDIå¤‰æ›é–‹å§‹")
        print(f"   å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}")
        
        midi_files = {}
        
        for track_name, audio_file in separated_files.items():
            if not os.path.exists(audio_file):
                print(f"   âš ï¸ {track_name}: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                continue
            
            print(f"\\n   ğŸ”„ {track_name} å‡¦ç†ä¸­...")
            
            try:
                if track_name in ["vocals", "other"]:
                    midi_file = self._convert_melody_track(audio_file, output_path, track_name)
                elif track_name == "drums":
                    midi_file = self._convert_drum_track(audio_file, output_path, track_name)
                elif track_name == "bass":
                    midi_file = self._convert_bass_track(audio_file, output_path, track_name)
                else:
                    midi_file = self._convert_melody_track(audio_file, output_path, track_name)
                
                if midi_file:
                    # é‡å­åŒ–é©ç”¨ï¼ˆå…ƒéŸ³æºã§BPMæ¤œå‡ºï¼‰
                    if self.quantizer:
                        print(f"      ğŸ¯ é‡å­åŒ–é©ç”¨ä¸­...")
                        bpm_source = self.original_audio_file if self.original_audio_file else audio_file
                        midi_file = self.quantizer.quantize_midi_file(midi_file, bpm_source, track_name)
                    
                    midi_files[track_name] = midi_file
                    print(f"      âœ… å¤‰æ›å®Œäº†: {Path(midi_file).name}")
                else:
                    print(f"      âŒ å¤‰æ›å¤±æ•—")
                    
            except Exception as e:
                print(f"      âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        
        print(f"\\nâœ… MIDIå¤‰æ›å®Œäº†: {len(midi_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ")
        return midi_files
    
    def _convert_melody_track(self, audio_file: str, output_dir: Path, track_name: str) -> str:
        """ãƒ¡ãƒ­ãƒ‡ã‚£ãƒˆãƒ©ãƒƒã‚¯å¤‰æ›"""
        if not BASIC_PITCH_AVAILABLE:
            return self._convert_with_librosa_melody(audio_file, output_dir, track_name)
        
        try:
            output_file = output_dir / f"{track_name}.mid"
            
            predict_and_save(
                [audio_file], str(output_dir), save_midi=True,
                sonify_midi=False, save_model_outputs=False, save_notes=False,
                model_or_model_path=ICASSP_2022_MODEL_PATH
            )
            
            generated_file = output_dir / f"{Path(audio_file).stem}_basic_pitch.mid"
            if generated_file.exists():
                generated_file.rename(output_file)
                return str(output_file)
            
            return None
        except Exception as e:
            print(f"         basic-pitch ã‚¨ãƒ©ãƒ¼: {e}")
            return self._convert_with_librosa_melody(audio_file, output_dir, track_name)
    
    def _convert_with_librosa_melody(self, audio_file: str, output_dir: Path, track_name: str) -> str:
        """librosa ãƒ¡ãƒ­ãƒ‡ã‚£å¤‰æ›"""
        try:
            y, sr = librosa.load(audio_file, sr=self.sample_rate)
            f0 = librosa.yin(y, fmin=80, fmax=800, sr=sr)
            times = librosa.frames_to_time(np.arange(len(f0)), sr=sr)
            
            midi_data = pretty_midi.PrettyMIDI()
            instrument = pretty_midi.Instrument(program=0)
            
            current_note = None
            note_start = None
            
            for time, freq in zip(times, f0):
                if freq > 100 and not np.isnan(freq):
                    midi_note = int(librosa.hz_to_midi(freq))
                    
                    if current_note is None or abs(midi_note - current_note) > 1:
                        if current_note is not None and note_start is not None:
                            if time - note_start >= 0.1:
                                note = pretty_midi.Note(80, current_note, note_start, time)
                                instrument.notes.append(note)
                        current_note = midi_note
                        note_start = time
                else:
                    if current_note is not None and note_start is not None:
                        if time - note_start >= 0.1:
                            note = pretty_midi.Note(80, current_note, note_start, time)
                            instrument.notes.append(note)
                        current_note = None
                        note_start = None
            
            midi_data.instruments.append(instrument)
            output_file = output_dir / f"{track_name}.mid"
            midi_data.write(str(output_file))
            
            print(f"         librosaå¤‰æ›: {len(instrument.notes)}å€‹ã®éŸ³ç¬¦")
            return str(output_file)
            
        except Exception as e:
            print(f"         librosaå¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _convert_drum_track(self, audio_file: str, output_dir: Path, track_name: str) -> str:
        """ãƒ‰ãƒ©ãƒ ãƒˆãƒ©ãƒƒã‚¯å¤‰æ›"""
        try:
            y, sr = librosa.load(audio_file, sr=self.sample_rate)
            
            onset_frames = librosa.onset.onset_detect(
                y=y, sr=sr, units='frames', hop_length=512,
                backtrack=True, pre_max=3, post_max=3,
                delta=0.2, wait=10
            )
            
            onset_times = librosa.frames_to_time(onset_frames, sr=sr)
            
            midi_data = pretty_midi.PrettyMIDI()
            instrument = pretty_midi.Instrument(program=0, is_drum=True)
            
            for onset_time in onset_times:
                note = pretty_midi.Note(
                    velocity=100, pitch=36, start=onset_time, end=onset_time + 0.1
                )
                instrument.notes.append(note)
            
            midi_data.instruments.append(instrument)
            output_file = output_dir / f"{track_name}.mid"
            midi_data.write(str(output_file))
            
            print(f"         ãƒ‰ãƒ©ãƒ å¤‰æ›: {len(onset_times)}å€‹ã®ãƒ’ãƒƒãƒˆ")
            return str(output_file)
            
        except Exception as e:
            print(f"         ãƒ‰ãƒ©ãƒ å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _convert_bass_track(self, audio_file: str, output_dir: Path, track_name: str) -> str:
        """ãƒ™ãƒ¼ã‚¹ãƒˆãƒ©ãƒƒã‚¯å¤‰æ›"""
        try:
            y, sr = librosa.load(audio_file, sr=self.sample_rate)
            f0 = librosa.yin(y, fmin=40, fmax=300, sr=sr)
            times = librosa.frames_to_time(np.arange(len(f0)), sr=sr)
            
            midi_data = pretty_midi.PrettyMIDI()
            instrument = pretty_midi.Instrument(program=33)  # Bass
            
            notes = []
            for time, freq in zip(times, f0):
                if freq > 50 and not np.isnan(freq):
                    midi_note = max(24, min(60, int(librosa.hz_to_midi(freq))))
                    notes.append((time, midi_note))
            
            if notes:
                for i in range(len(notes) - 1):
                    start_time, pitch = notes[i]
                    end_time = notes[i + 1][0]
                    if end_time - start_time >= 0.2:
                        note = pretty_midi.Note(80, pitch, start_time, end_time)
                        instrument.notes.append(note)
            
            midi_data.instruments.append(instrument)
            output_file = output_dir / f"{track_name}.mid"
            midi_data.write(str(output_file))
            
            print(f"         ãƒ™ãƒ¼ã‚¹å¤‰æ›: {len(instrument.notes)}å€‹ã®éŸ³ç¬¦")
            return str(output_file)
            
        except Exception as e:
            print(f"         ãƒ™ãƒ¼ã‚¹å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def merge_midi_tracks(self, midi_files: Dict[str, str], output_file: str = None, include_tracks: List[str] = None) -> str:
        """MIDIãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµ±åˆ"""
        if output_file is None:
            first_file = Path(next(iter(midi_files.values())))
            output_file = first_file.parent / "merged_composition.mid"
        
        print(f"\\nğŸµ MIDIãƒˆãƒ©ãƒƒã‚¯çµ±åˆ")
        print(f"   å‡ºåŠ›: {output_file}")
        
        if include_tracks:
            print(f"   å¯¾è±¡ãƒˆãƒ©ãƒƒã‚¯: {', '.join(include_tracks)}")
            filtered_files = {k: v for k, v in midi_files.items() if k in include_tracks}
        else:
            filtered_files = midi_files
        
        merged_midi = pretty_midi.PrettyMIDI()
        
        for track_name, midi_path in filtered_files.items():
            try:
                track_midi = pretty_midi.PrettyMIDI(midi_path)
                for instrument in track_midi.instruments:
                    merged_midi.instruments.append(instrument)
                print(f"   âœ… {track_name}: {len(track_midi.instruments)}æ¥½å™¨è¿½åŠ ")
            except Exception as e:
                print(f"   âŒ {track_name}: ã‚¨ãƒ©ãƒ¼ - {e}")
        
        merged_midi.write(str(output_file))
        
        total_notes = sum(len(inst.notes) for inst in merged_midi.instruments)
        end_time = merged_midi.get_end_time()
        
        print(f"   ğŸ“Š çµ±åˆçµæœ:")
        print(f"     æ¥½å™¨æ•°: {len(merged_midi.instruments)}")
        print(f"     ç·éŸ³ç¬¦æ•°: {total_notes}")
        print(f"     æ¼”å¥æ™‚é–“: {end_time:.2f}ç§’")
        
        return str(output_file)
    
    def analyze_midi_files(self, midi_files: Dict[str, str]) -> Dict:
        """MIDIåˆ†æ"""
        print(f"\\nğŸ“Š MIDIåˆ†æ")
        analysis = {}
        
        for track_name, midi_path in midi_files.items():
            try:
                midi_data = pretty_midi.PrettyMIDI(midi_path)
                note_count = sum(len(inst.notes) for inst in midi_data.instruments)
                duration = midi_data.get_end_time()
                instrument_count = len(midi_data.instruments)
                file_size = Path(midi_path).stat().st_size / 1024  # KB
                
                analysis[track_name] = {
                    "note_count": note_count,
                    "duration": duration,
                    "instrument_count": instrument_count,
                    "file_size_kb": file_size
                }
                
                print(f"   {track_name}:")
                print(f"     éŸ³ç¬¦æ•°: {note_count}")
                print(f"     é•·ã•: {duration:.2f}ç§’")
                print(f"     æ¥½å™¨æ•°: {instrument_count}")
                print(f"     ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:.2f}KB")
                
            except Exception as e:
                print(f"   âŒ {track_name}: åˆ†æã‚¨ãƒ©ãƒ¼ - {e}")
                
        return analysis

def find_enhanced_separation_results(base_dir: str = None) -> Dict[str, Dict[str, str]]:
    """
    é«˜å“è³ªåˆ†é›¢çµæœã‚’æ¤œç´¢
    
    Args:
        base_dir: æ¤œç´¢ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        
    Returns:
        {model_name: {track: file_path}} å½¢å¼ã®è¾æ›¸
    """
    if base_dir is None:
        base_dir = Path.home() / "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ" / "conversion_music"
    
    base_path = Path(base_dir)
    results = {}
    
    # æ¨™æº–çš„ãªåˆ†é›¢çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¤œç´¢
    search_patterns = [
        "input_separated_enhanced",
        "*_separated_enhanced", 
        "*_separated",
        "*_comparison"
    ]
    
    for pattern in search_patterns:
        for sep_dir in base_path.glob(pattern):
            if not sep_dir.is_dir():
                continue
                
            print(f"ğŸ” æ¤œç´¢ä¸­: {sep_dir.name}")
            
            # ãƒ¢ãƒ‡ãƒ«åˆ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¤œç´¢
            for model_dir in sep_dir.iterdir():
                if not model_dir.is_dir():
                    continue
                
                model_name = model_dir.name
                print(f"   ãƒ¢ãƒ‡ãƒ«: {model_name}")
                
                # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
                audio_files = find_audio_files_in_model_dir(model_dir)
                
                if audio_files:
                    results[f"{sep_dir.name}/{model_name}"] = audio_files
                    print(f"     âœ… ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(audio_files)}")
                    for track, file_path in audio_files.items():
                        print(f"       {track}: {Path(file_path).name}")
    
    return results

def find_audio_files_in_model_dir(model_dir: Path) -> Dict[str, str]:
    """ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
    audio_files = {}
    
    # è¤‡æ•°ã®éšå±¤æ§‹é€ ã«å¯¾å¿œ
    search_dirs = [
        model_dir,  # ç›´æ¥
        model_dir / "input",  # htdemucs/input
        model_dir / "input_preprocessed",  # htdemucs_ft/input_preprocessed
    ]
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚‚æ¤œç´¢
    for subdir in model_dir.iterdir():
        if subdir.is_dir():
            search_dirs.append(subdir)
    
    track_names = ["vocals", "drums", "bass", "other", "piano", "guitar"]
    
    for search_dir in search_dirs:
        if not search_dir.exists():
            continue
            
        for track in track_names:
            for ext in [".wav", ".mp3", ".flac"]:
                audio_file = search_dir / f"{track}{ext}"
                if audio_file.exists() and track not in audio_files:
                    audio_files[track] = str(audio_file)
    
    return audio_files

def convert_enhanced_separation_to_midi(separation_results: Dict[str, Dict[str, str]], 
                                      output_base_dir: str = None,
                                      quantization_settings: QuantizationSettings = None) -> Dict[str, Dict]:
    """
    é«˜å“è³ªåˆ†é›¢çµæœã‚’MIDIå¤‰æ›
    
    Args:
        separation_results: åˆ†é›¢çµæœè¾æ›¸
        output_base_dir: å‡ºåŠ›ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        
    Returns:
        MIDIå¤‰æ›çµæœè¾æ›¸
    """
    if output_base_dir is None:
        output_base_dir = Path.cwd() / "enhanced_midi_results"
    
    output_base_path = Path(output_base_dir)
    output_base_path.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸ¼ é«˜å“è³ªåˆ†é›¢MIDIå¤‰æ›é–‹å§‹")
    print(f"   å‡ºåŠ›ãƒ™ãƒ¼ã‚¹: {output_base_dir}")
    print(f"   å¯¾è±¡æ•°: {len(separation_results)}")
    
    conversion_results = {}
    
    for model_key, audio_files in separation_results.items():
        print(f"\n--- {model_key} MIDIå¤‰æ› ---")
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
        safe_model_key = model_key.replace("/", "_").replace("\\", "_")
        model_output_dir = output_base_path / f"{safe_model_key}_midi"
        
        try:
            # å…ƒéŸ³æºãƒ‘ã‚¹ã‚’å–å¾—ï¼ˆBPMæ¤œå‡ºç”¨ï¼‰
            work_dir = Path.home() / "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ" / "conversion_music"
            original_audio = work_dir / "input.m4a"
            
            # MIDIå¤‰æ›å®Ÿè¡Œï¼ˆå…ƒéŸ³æºãƒ‘ã‚¹ã‚’æ¸¡ã™ï¼‰
            converter = MIDIConverter(quantization_settings, str(original_audio) if original_audio.exists() else None)
            midi_files = converter.convert_separated_tracks(audio_files, str(model_output_dir))
            
            if midi_files:
                # MIDIåˆ†æ
                analysis = converter.analyze_midi_files(midi_files)
                
                # çµ±åˆMIDIä½œæˆï¼ˆå…¨ãƒˆãƒ©ãƒƒã‚¯ï¼‰
                merged_midi_all = model_output_dir / "merged_composition_all.mid"
                converter.merge_midi_tracks(midi_files, str(merged_midi_all))
                
                # ãƒœãƒ¼ã‚«ãƒ«+ãã®ä»–ã®ã¿ã®çµ±åˆMIDIä½œæˆ
                merged_midi_vocal_other = model_output_dir / "merged_composition_vocal_other.mid"
                converter.merge_midi_tracks(midi_files, str(merged_midi_vocal_other), 
                                          include_tracks=["vocals", "other"])
                
                conversion_results[model_key] = {
                    "midi_files": midi_files,
                    "analysis": analysis,
                    "merged_midi_all": str(merged_midi_all),
                    "merged_midi_vocal_other": str(merged_midi_vocal_other),
                    "output_dir": str(model_output_dir)
                }
                
                print(f"   âœ… å¤‰æ›å®Œäº†: {len(midi_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
                
            else:
                print(f"   âŒ å¤‰æ›å¤±æ•—")
                conversion_results[model_key] = {"error": "MIDIå¤‰æ›å¤±æ•—"}
                
        except Exception as e:
            print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            conversion_results[model_key] = {"error": str(e)}
    
    return conversion_results

def create_conversion_comparison_report(results: Dict[str, Dict], output_dir: str):
    """MIDIå¤‰æ›æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆä½œæˆ"""
    print(f"\nğŸ“Š MIDIå¤‰æ›æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")
    
    # æˆåŠŸã—ãŸçµæœã®ã¿æŠ½å‡º
    valid_results = {k: v for k, v in results.items() if "error" not in v}
    
    if not valid_results:
        print("âŒ æœ‰åŠ¹ãªçµæœãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿æº–å‚™
    report_data = {
        "timestamp": "2025-08-14T23:58:00",
        "total_conversions": len(results),
        "successful_conversions": len(valid_results),
        "results": {}
    }
    
    # å„ãƒ¢ãƒ‡ãƒ«ã®çµæœã‚’åˆ†æ
    for model_key, result in valid_results.items():
        if "analysis" in result:
            analysis = result["analysis"]
            
            # çµ±è¨ˆè¨ˆç®—
            total_notes = sum(track.get("note_count", 0) for track in analysis.values())
            avg_duration = sum(track.get("duration", 0) for track in analysis.values()) / len(analysis)
            
            report_data["results"][model_key] = {
                "midi_files": len(result["midi_files"]),
                "total_notes": total_notes,
                "average_duration": avg_duration,
                "tracks": list(analysis.keys()),
                "merged_midi_all": result["merged_midi_all"],
                "merged_midi_vocal_other": result["merged_midi_vocal_other"]
            }
    
    # JSONä¿å­˜
    report_file = Path(output_dir) / "midi_conversion_report.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report_data, f, indent=2, ensure_ascii=False)
    
    # çµæœè¡¨ç¤º
    print(f"ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_file.name}")
    print(f"\nğŸ“Š å¤‰æ›çµæœã‚µãƒãƒªãƒ¼:")
    print(f"   æˆåŠŸ: {len(valid_results)}/{len(results)}")
    
    for model_key, model_data in report_data["results"].items():
        print(f"   {model_key}:")
        print(f"     éŸ³ç¬¦æ•°: {model_data['total_notes']}")
        print(f"     å¹³å‡æ™‚é–“: {model_data['average_duration']:.1f}ç§’")
        print(f"     çµ±åˆMIDIï¼ˆå…¨ï¼‰: {Path(model_data['merged_midi_all']).name}")
        print(f"     çµ±åˆMIDIï¼ˆvocal+otherï¼‰: {Path(model_data['merged_midi_vocal_other']).name}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(description="é«˜å“è³ªéŸ³æºåˆ†é›¢çµæœã‹ã‚‰MIDIå¤‰æ›")
    parser.add_argument("--input-dir", "-i", type=str, help="å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--output-dir", "-o", type=str, help="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª") 
    parser.add_argument("--model", "-m", type=str, help="ç‰¹å®šãƒ¢ãƒ‡ãƒ«ã®ã¿å‡¦ç†")
    parser.add_argument("--quantize", action="store_true", help="MIDIé‡å­åŒ–ã‚’æœ‰åŠ¹åŒ–")
    parser.add_argument("--grid", type=str, default="thirtysecond", choices=["quarter", "eighth", "sixteenth", "thirtysecond"], help="é‡å­åŒ–ã‚°ãƒªãƒƒãƒ‰è§£åƒåº¦")
    parser.add_argument("--strength", type=float, default=0.8, help="é‡å­åŒ–å¼·åº¦ (0.0-1.0)")
    parser.add_argument("--bpm", type=float, help="æ‰‹å‹•BPMæŒ‡å®šï¼ˆè‡ªå‹•æ¤œå‡ºã‚ˆã‚Šå„ªå…ˆï¼‰")
    
    args = parser.parse_args()
    
    print("ğŸ¼ é«˜å“è³ªåˆ†é›¢ â†’ MIDIå¤‰æ›ã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 50)
    
    # ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    work_dir = Path.home() / "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ" / "conversion_music"
    print(f"ğŸ“ ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {work_dir}")
    
    # é«˜å“è³ªåˆ†é›¢çµæœæ¤œç´¢
    separation_results = find_enhanced_separation_results(args.input_dir or str(work_dir))
    
    if not separation_results:
        print("\nâŒ é«˜å“è³ªåˆ†é›¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("å…ˆã« enhanced_music_separation.py ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:")
        print("python enhanced_music_separation.py --model htdemucs_ft --quality high --input input.m4a")
        return
    
    print(f"\nğŸµ è¦‹ã¤ã‹ã£ãŸåˆ†é›¢çµæœ: {len(separation_results)}")
    
    # ç‰¹å®šãƒ¢ãƒ‡ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    if args.model:
        filtered_results = {k: v for k, v in separation_results.items() 
                          if args.model in k.lower()}
        if filtered_results:
            separation_results = filtered_results
            print(f"ğŸ” ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨: {args.model} â†’ {len(separation_results)}ä»¶")
        else:
            print(f"âš ï¸ æŒ‡å®šãƒ¢ãƒ‡ãƒ« '{args.model}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # é‡å­åŒ–è¨­å®š
    quantization_settings = None
    if args.quantize:
        quantization_settings = QuantizationSettings(
            enabled=True,
            grid_resolution=args.grid,
            strength=args.strength,
            auto_detect_bpm=args.bpm is None,
            manual_bpm=args.bpm
        )
        print(f"ğŸ¯ é‡å­åŒ–è¨­å®š: {args.grid}éŸ³ç¬¦, å¼·åº¦{args.strength}, BPM{args.bpm or 'è‡ªå‹•æ¤œå‡º'}")
    
    # MIDIå¤‰æ›å®Ÿè¡Œ
    output_dir = args.output_dir or str(work_dir / "enhanced_midi_results")
    conversion_results = convert_enhanced_separation_to_midi(separation_results, output_dir, quantization_settings)
    
    # æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    create_conversion_comparison_report(conversion_results, output_dir)
    
    print(f"\nâœ… é«˜å“è³ªåˆ†é›¢MIDIå¤‰æ›å®Œäº†!")
    print(f"   çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}")
    
    # æˆåŠŸã—ãŸçµæœã®è©³ç´°è¡¨ç¤º
    successful_results = [k for k, v in conversion_results.items() if "error" not in v]
    if successful_results:
        print(f"\nğŸµ ç”Ÿæˆã•ã‚ŒãŸMIDIãƒ•ã‚¡ã‚¤ãƒ«:")
        for model_key in successful_results:
            result = conversion_results[model_key]
            print(f"   {model_key}:")
            print(f"     ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {Path(result['output_dir']).name}")
            print(f"     ğŸ¼ çµ±åˆMIDIï¼ˆå…¨ï¼‰: {Path(result['merged_midi_all']).name}")
            print(f"     ğŸµ çµ±åˆMIDIï¼ˆvocal+otherï¼‰: {Path(result['merged_midi_vocal_other']).name}")

if __name__ == "__main__":
    main()